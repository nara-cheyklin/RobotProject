ðŸ¤– Hand-Gesture-Controlled Autonomous Robot Navigation

ROS 2 | SLAM | Nav2 | Computer Vision | Human-Robot Interaction


ðŸ“Œ Project Summary
This project integrates autonomous mobile robot navigation with real-time hand gesture control, enabling intuitive human-robot interaction in shared environments.
Instead of using a keyboard or joystick, users visually select waypoints in RViz and control execution (start, pause, resume, stop) through dynamic hand gestures detected via computer vision.


The system demonstrates advanced integration of:
- ROS 2 distributed architecture
- SLAM-based mapping
- Autonomous path planning
- Action server communication
- Real-time perception with MediaPipe
